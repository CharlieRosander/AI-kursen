{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM73yRDUiYtW",
        "outputId": "a64b621b-3537-4848-8b41-9e28960add6c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw6KVb9diWn1"
      },
      "outputs": [],
      "source": [
        "# !unzip gdrive/MyDrive/data.zip > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38UZ0eR5iQto"
      },
      "source": [
        "# Cat-Dog classification using transfer learning\n",
        "###### Charlie Rosander 2023-09\n",
        "A while back I made a Cat-Dog-CNN project, which was a simple CNN model classifying cats and dogs. Running 100 Epochs I would get around 80-85% accuracy, so now I want to try the same dataset but with transfer learning, to see if I can get a better result with fewer epochs etc. We will be using MobileNetV2 as our base model.\n",
        "\n",
        "The dataset is from Kaggle: https://www.microsoft.com/en-us/download/details.aspx?id=54765"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6yw4eJRiQtp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from numba import jit, cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDZ5yxKAiQtp"
      },
      "source": [
        "We start by preparing some variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4-CO_uQiQtp",
        "outputId": "cf5b5d47-f4e4-49c3-f729-1be6dd813f7e"
      },
      "outputs": [],
      "source": [
        "# Preparing directory vars\n",
        "base_dir = os.getcwd() + '/data'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "print(f\"\"\"\n",
        "{base_dir},\n",
        "{train_dir},\n",
        "{test_dir}\n",
        "\"\"\")\n",
        "\n",
        "# Prepare image parameter vars\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (96, 96)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4q1ycWRiQtq"
      },
      "source": [
        "### Data preprocessing\n",
        "Here we use the ImageDataGenerator to load the images from the directories. I have split the data up into train, val and test in the directories, each with their respective subfolders (cat/dog).\n",
        "\n",
        "We are also using MobileNetV2's preprocessing method as the preprocessing_function.\n",
        "ImageDataGenerator automatically labels the images into classes based on the subfolders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxgUg6QIiQtq",
        "outputId": "9e7fa4fc-2307-4de5-a369-8795abedc529"
      },
      "outputs": [],
      "source": [
        "# Preparing the preprocess method\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "# Create an ImageDataGenerator object with rescaling and validation split\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2  # 20% for validation\n",
        ")\n",
        "\n",
        "# Create a test ImageDataGenerator object only with rescaling\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "# Training data: 80% from train directory\n",
        "train_gen = train_datagen.flow_from_directory(train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"training\"  # set as training data\n",
        ")\n",
        "\n",
        "# Validation data: 20% from train directory\n",
        "val_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"validation\"  # set as validation data\n",
        ")\n",
        "\n",
        "# Test data: Take all images from test directory\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4hv_Wu4iQtq"
      },
      "source": [
        "### Inspecting the data\n",
        "We will inspect the data a bit more to see that everything is in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz2BIbBViQtr",
        "outputId": "bdf5072a-f842-483b-caed-16c9a53dceb8"
      },
      "outputs": [],
      "source": [
        "# Here we inspect the classes to verify that they are correct.\n",
        "\n",
        "print(\"Training class indices:\", train_gen.class_indices)\n",
        "print(\"Validation class indices:\", val_gen.class_indices)\n",
        "print(\"Test class indices:\", test_gen.class_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNtzxNmziQtr",
        "outputId": "d38bf1e7-cc89-41d6-9489-a90c8d2040a5"
      },
      "outputs": [],
      "source": [
        "# Inspect batch size and shape\n",
        "for image_batch, label_batch in train_gen:\n",
        "    print(\"Image batch shape:\", image_batch.shape)\n",
        "    print(\"Label batch shape:\", label_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "dHSust6diQtr",
        "outputId": "fb439934-9ef1-4b36-eb0a-2d1424ae2f0c"
      },
      "outputs": [],
      "source": [
        "# Inspecting the images. Looks absolutely fantastic. And kinda creepy.\n",
        "x_batch, y_batch = next(train_gen)\n",
        "\n",
        "plt.figure(figsize=(10, 10), facecolor='white')\n",
        "for i in range(6):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.title(f\"Class: {y_batch[i]}\")\n",
        "    plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNJnHJzqiQtr"
      },
      "source": [
        "### Creating the model, using the base model MobileNetV2.\n",
        "We will use the pretrained model MobileNetV2 as our base model, and we will not include the top layer as we will add our own classifier layer and train it ourselves, as well as freeze the base model so we don't have to retrain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcsHK9d1iQtr",
        "outputId": "935f3fce-8966-40ee-bf59-082428f5cc27"
      },
      "outputs": [],
      "source": [
        "# Creating the base model MobileNetV2\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMyvn9P6iQtr",
        "outputId": "f313ddf5-91c4-4b92-8536-3960ab3e9385"
      },
      "outputs": [],
      "source": [
        "# # Here we retrieve a batch of images and their labels from train_gen, \n",
        "# passes them through the base model to extract the features and then prints the shape\n",
        "\n",
        "image_batch, label_batch = next(iter(train_gen))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hko7ps9AiQts"
      },
      "outputs": [],
      "source": [
        "# Freezing the base model\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVJCj0sLiQts",
        "outputId": "a3c13750-4bb6-4267-ed0e-ea478e40761f"
      },
      "outputs": [],
      "source": [
        "# Inspect the base model\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdhc6DO6iQts"
      },
      "source": [
        "### Classification head\n",
        "We need to add a classification head to the model, and we will convert the features to a single 1280-element vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSjtfKlIiQts",
        "outputId": "51e0094f-1686-4f93-a4e4-8d1b613b3ea2"
      },
      "outputs": [],
      "source": [
        "# Converting the features to a single 1280-element vector per image\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzNj7fduiQts",
        "outputId": "c998dbc3-3a04-4b59-820f-82ffc343e2c5"
      },
      "outputs": [],
      "source": [
        "# Adding a prediction layer\n",
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8kbY8kHiQts"
      },
      "source": [
        "### Putting it all together\n",
        "We will now put all the parts together, as well as some last minute data-augmentation because I forgot to write it earlier in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svs57ihoiQtt",
        "outputId": "c1b9807d-c606-47f7-8fc2-3f200999df6b"
      },
      "outputs": [],
      "source": [
        "# Some data augmentation\n",
        "data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(\n",
        "    'horizontal'), tf.keras.layers.RandomRotation(0.2),])\n",
        "\n",
        "inputs = tf.keras.Input(shape=(96, 96, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt0-O20eiQtt"
      },
      "source": [
        "We can see in the output above that we now have 1,281 trainable parameters, which is from the classification head we added. These will be trained, while the base model will be frozen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXvoRBnmiQtt"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSc7GRBjiQtt",
        "outputId": "fbad7b2c-5451-48be-86eb-9436e861ff1e"
      },
      "outputs": [],
      "source": [
        "# Var for the number of epochs\n",
        "epoch_num = 10\n",
        "\n",
        "# Train the actual model\n",
        "history = model.fit(train_gen, epochs=epoch_num, validation_data=val_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting and evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppt3sNzdiQtt",
        "outputId": "45a9a532-09cf-45a6-a155-71f4e10ee0e0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjyBWQCGsuVn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS2bvsdsstqu",
        "outputId": "e403e500-dc90-49ad-81e5-a4adeca70b1f"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_loss, test_acc = model.evaluate(test_gen, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "print('\\nTest loss:', test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOGd1p6eiQtt",
        "outputId": "b40b522d-92cc-4cee-95e9-0d5589ff7c96"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = model.predict(test_gen)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Get the true labels\n",
        "y_true = test_gen.classes\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(cm, annot=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
